{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Copyright (c) Microsoft Corporation. All rights reserved.\n\nLicensed under the MIT License."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Tutorial #2:  Deploy an image classification model in Azure Container Instance (ACI)\n\nThis tutorial is **part two of a two-part tutorial series**. In the [previous tutorial](img-classification-part1-training.ipynb), you trained machine learning models and then registered a model in your workspace on the cloud.  \n\nNow, you're ready to deploy the model as a web service in [Azure Container Instances](https://docs.microsoft.com/azure/container-instances/) (ACI). A web service is an image, in this case a Docker image, that encapsulates the scoring logic and the model itself. \n\nIn this part of the tutorial, you use Azure Machine Learning service (Preview) to:\n\n> * Set up your testing environment\n> * Retrieve the model from your workspace\n> * Test the model locally\n> * Deploy the model to ACI\n> * Test the deployed model\n\nACI is not ideal for production deployments, but it is great for testing and understanding the workflow. For scalable production deployments, consider using AKS.\n\n\n## Prerequisites\n\nComplete the model training in the [Tutorial #1: Train an image classification model with Azure Machine Learning](train-models.ipynb) notebook.  \n\n"
    },
    {
      "metadata": {
        "tags": [
          "register model from file"
        ],
        "trusted": false
      },
      "cell_type": "code",
      "source": "# If you did NOT complete the tutorial, you can instead run this cell \n# This will register a model and download the data needed for this tutorial\n# These prerequisites are created in the training tutorial\n# Feel free to skip this cell if you completed the training tutorial \n\n# register a model\nfrom azureml.core import Workspace\nws = Workspace.from_config()\n\nfrom azureml.core.model import Model\n\nmodel_name = \"sklearn_mnist\"\nmodel = Model.register(model_path=\"sklearn_mnist_model.pkl\",\n                        model_name=model_name,\n                        tags={\"data\": \"mnist\", \"model\": \"classification\"},\n                        description=\"Mnist handwriting recognition\",\n                        workspace=ws)\n\n# download test data\nimport os\nimport urllib.request\n\nos.makedirs('./data', exists_ok=True)\n\nurllib.request.urlretrieve('http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz', filename='./data/test-images.gz')\nurllib.request.urlretrieve('http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz', filename='./data/test-labels.gz')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Set up the environment\n\nStart by setting up a testing environment.\n\n### Import packages\n\nImport the Python packages needed for this tutorial."
    },
    {
      "metadata": {
        "tags": [
          "check version"
        ],
        "trusted": false
      },
      "cell_type": "code",
      "source": "%matplotlib inline\nimport numpy as np\nimport matplotlib\nimport matplotlib.pyplot as plt\n \nimport azureml\nfrom azureml.core import Workspace, Run\n\n# display the core SDK version number\nprint(\"Azure ML SDK Version: \", azureml.core.VERSION)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Retrieve the model\n\nYou registered a model in your workspace in the previous tutorial. Now, load this workspace and download the model to your local directory."
    },
    {
      "metadata": {
        "tags": [
          "load workspace",
          "download model"
        ],
        "trusted": false
      },
      "cell_type": "code",
      "source": "from azureml.core import Workspace\nfrom azureml.core.model import Model\n\nws = Workspace.from_config()\nmodel=Model(ws, 'sklearn_mnist')\nmodel.download(target_dir='.', exist_ok=True)\nimport os \n# verify the downloaded model file\nos.stat('./sklearn_mnist_model.pkl')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Test model locally\n\nBefore deploying, make sure your model is working locally by:\n* Loading test data\n* Predicting test data\n* Examining the confusion matrix\n\n### Load test data\n\nLoad the test data from the **./data/** directory created during the training tutorial."
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "from utils import load_data\n\n# note we also shrink the intensity values (X) from 0-255 to 0-1. This helps the neural network converge faster\nX_test = load_data('./data/test-images.gz', False) / 255.0\ny_test = load_data('./data/test-labels.gz', True).reshape(-1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Predict test data\n\nFeed the test dataset to the model to get predictions."
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "import pickle\nfrom sklearn.externals import joblib\n\nclf = joblib.load('./sklearn_mnist_model.pkl')\ny_hat = clf.predict(X_test)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "###  Examine the confusion matrix\n\nGenerate a confusion matrix to see how many samples from the test set are classified correctly. Notice the mis-classified value for the incorrect predictions."
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "from sklearn.metrics import confusion_matrix\n\nconf_mx = confusion_matrix(y_test, y_hat)\nprint(conf_mx)\nprint('Overall accuracy:', np.average(y_hat == y_test))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Use `matplotlib` to display the confusion matrix as a graph. In this graph, the X axis represents the actual values, and the Y axis represents the predicted values. The color in each grid represents the error rate. The lighter the color, the higher the error rate is. For example, many 5's are mis-classified as 3's. Hence you see a bright grid at (5,3)."
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "# normalize the diagnal cells so that they don't overpower the rest of the cells when visualized\nrow_sums = conf_mx.sum(axis=1, keepdims=True)\nnorm_conf_mx = conf_mx / row_sums\nnp.fill_diagonal(norm_conf_mx, 0)\n\nfig = plt.figure(figsize=(8,5))\nax = fig.add_subplot(111)\ncax = ax.matshow(norm_conf_mx, cmap=plt.cm.bone)\nticks = np.arange(0, 10, 1)\nax.set_xticks(ticks)\nax.set_yticks(ticks)\nax.set_xticklabels(ticks)\nax.set_yticklabels(ticks)\nfig.colorbar(cax)\nplt.ylabel('true labels', fontsize=14)\nplt.xlabel('predicted values', fontsize=14)\nplt.savefig('conf.png')\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Deploy as web service\n\nOnce you've tested the model and are satisfied with the results, deploy the model as a web service hosted in ACI. \n\nTo build the correct environment for ACI, provide the following:\n* A scoring script to show how to use the model\n* An environment file to show what packages need to be installed\n* A configuration file to build the ACI\n* The model you trained before\n\n### Create scoring script\n\nCreate the scoring script, called score.py, used by the web service call to show how to use the model.\n\nYou must include two required functions into the scoring script:\n* The `init()` function, which typically loads the model into a global object. This function is run only once when the Docker container is started. \n\n* The `run(input_data)` function uses the model to predict a value based on the input data. Inputs and outputs to the run typically use JSON for serialization and de-serialization, but other formats are supported.\n"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "%%writefile score.py\nimport json\nimport numpy as np\nimport os\nimport pickle\nfrom sklearn.externals import joblib\nfrom sklearn.linear_model import LogisticRegression\n\nfrom azureml.core.model import Model\n\ndef init():\n    global model\n    # retreive the path to the model file using the model name\n    model_path = Model.get_model_path('sklearn_mnist')\n    model = joblib.load(model_path)\n\ndef run(raw_data):\n    data = np.array(json.loads(raw_data)['data'])\n    # make prediction\n    y_hat = model.predict(data)\n    # you can return any data type as long as it is JSON-serializable\n    return y_hat.tolist()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Create environment file\n\nNext, create an environment file, called myenv.yml, that specifies all of the script's package dependencies. This file is used to ensure that all of those dependencies are installed in the Docker image. This model needs `scikit-learn` and `azureml-sdk`."
    },
    {
      "metadata": {
        "tags": [
          "set conda dependencies"
        ],
        "trusted": false
      },
      "cell_type": "code",
      "source": "from azureml.core.conda_dependencies import CondaDependencies \n\nmyenv = CondaDependencies()\nmyenv.add_conda_package(\"scikit-learn\")\n\nwith open(\"myenv.yml\",\"w\") as f:\n    f.write(myenv.serialize_to_string())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Review the content of the `myenv.yml` file."
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "with open(\"myenv.yml\",\"r\") as f:\n    print(f.read())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Create configuration file\n\nCreate a deployment configuration file and specify the number of CPUs and gigabyte of RAM needed for your ACI container. While it depends on your model, the default of 1 core and 1 gigabyte of RAM is usually sufficient for many models. If you feel you need more later, you would have to recreate the image and redeploy the service."
    },
    {
      "metadata": {
        "tags": [
          "configure web service",
          "aci"
        ],
        "trusted": false
      },
      "cell_type": "code",
      "source": "from azureml.core.webservice import AciWebservice\n\naciconfig = AciWebservice.deploy_configuration(cpu_cores=1, \n                                               memory_gb=1, \n                                               tags={\"data\": \"MNIST\",  \"method\" : \"sklearn\"}, \n                                               description='Predict MNIST with sklearn')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Deploy in ACI\nEstimated time to complete: **about 7-8 minutes**\n\nConfigure the image and deploy. The following code goes through these steps:\n\n1. Build an image using:\n   * The scoring file (`score.py`)\n   * The environment file (`myenv.yml`)\n   * The model file\n1. Register that image under the workspace. \n1. Send the image to the ACI container.\n1. Start up a container in ACI using the image.\n1. Get the web service HTTP endpoint."
    },
    {
      "metadata": {
        "tags": [
          "configure image",
          "create image",
          "deploy web service",
          "aci"
        ],
        "trusted": false
      },
      "cell_type": "code",
      "source": "%%time\nfrom azureml.core.webservice import Webservice\nfrom azureml.core.image import ContainerImage\n\n# configure the image\nimage_config = ContainerImage.image_configuration(execution_script=\"score.py\", \n                                                  runtime=\"python\", \n                                                  conda_file=\"myenv.yml\")\n\nservice = Webservice.deploy_from_model(workspace=ws,\n                                       name='sklearn-mnist-svc',\n                                       deployment_config=aciconfig,\n                                       models=[model],\n                                       image_config=image_config)\n\nservice.wait_for_deployment(show_output=True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Get the scoring web service's HTTP endpoint, which accepts REST client calls. This endpoint can be shared with anyone who wants to test the web service or integrate it into an application."
    },
    {
      "metadata": {
        "tags": [
          "get scoring uri"
        ],
        "trusted": false
      },
      "cell_type": "code",
      "source": "print(service.scoring_uri)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Test deployed service\n\nEarlier you scored all the test data with the local version of the model. Now, you can test the deployed model with a random sample of 30 images from the test data.  \n\nThe following code goes through these steps:\n1. Send the data as a JSON array to the web service hosted in ACI. \n\n1. Use the SDK's `run` API to invoke the service. You can also make raw calls using any HTTP tool such as curl.\n\n1. Print the returned predictions and plot them along with the input images. Red font and inverse image (white on black) is used to highlight the misclassified samples. \n\n Since the model accuracy is high, you might have to run the following code a few times before you can see a misclassified sample."
    },
    {
      "metadata": {
        "tags": [
          "score web service"
        ],
        "trusted": false
      },
      "cell_type": "code",
      "source": "import json\n\n# find 30 random samples from test set\nn = 30\nsample_indices = np.random.permutation(X_test.shape[0])[0:n]\n\ntest_samples = json.dumps({\"data\": X_test[sample_indices].tolist()})\ntest_samples = bytes(test_samples, encoding='utf8')\n\n# predict using the deployed model\nresult = service.run(input_data=test_samples)\n\n# compare actual value vs. the predicted values:\ni = 0\nplt.figure(figsize = (20, 1))\n\nfor s in sample_indices:\n    plt.subplot(1, n, i + 1)\n    plt.axhline('')\n    plt.axvline('')\n    \n    # use different color for misclassified sample\n    font_color = 'red' if y_test[s] != result[i] else 'black'\n    clr_map = plt.cm.gray if y_test[s] != result[i] else plt.cm.Greys\n    \n    plt.text(x=10, y =-10, s=result[i], fontsize=18, color=font_color)\n    plt.imshow(X_test[s].reshape(28, 28), cmap=clr_map)\n    \n    i = i + 1\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "You can also send raw HTTP request to test the web service."
    },
    {
      "metadata": {
        "tags": [
          "score web service"
        ],
        "trusted": false
      },
      "cell_type": "code",
      "source": "import requests\nimport json\n\n# send a random row from the test set to score\nrandom_index = np.random.randint(0, len(X_test)-1)\ninput_data = \"{\\\"data\\\": [\" + str(list(X_test[random_index])) + \"]}\"\n\nheaders = {'Content-Type':'application/json'}\n\n# for AKS deployment you'd need to the service key in the header as well\n# api_key = service.get_key()\n# headers = {'Content-Type':'application/json',  'Authorization':('Bearer '+ api_key)} \n\nresp = requests.post(service.scoring_uri, input_data, headers=headers)\n\nprint(\"POST to url\", service.scoring_uri)\n#print(\"input data:\", input_data)\nprint(\"label:\", y_test[random_index])\nprint(\"prediction:\", resp.text)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Clean up resources\n\nTo keep the resource group and workspace for other tutorials and exploration, you can delete only the ACI deployment using this API call:"
    },
    {
      "metadata": {
        "tags": [
          "delete web service"
        ],
        "trusted": false
      },
      "cell_type": "code",
      "source": "service.delete()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "\nIf you're not going to use what you've created here, delete the resources you just created with this quickstart so you don't incur any charges. In the Azure portal, select and delete your resource group. You can also keep the resource group, but delete a single workspace by displaying the workspace properties and selecting the Delete button.\n\n\n## Next steps\n\nIn this Azure Machine Learning tutorial, you used Python to:\n\n> * Set up your testing environment\n> * Retrieve the model from your workspace\n> * Test the model locally\n> * Deploy the model to ACI\n> * Test the deployed model\n \nYou can also try out the [Automatic algorithm selection tutorial](03.auto-train-models.ipynb) to see how Azure Machine Learning can auto-select and tune the best algorithm for your model and build that model for you."
    }
  ],
  "metadata": {
    "authors": [
      {
        "name": "roastala"
      }
    ],
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    },
    "msauthor": "sgilley"
  },
  "nbformat": 4,
  "nbformat_minor": 2
}